{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of a twin boundary\n",
    "---\n",
    "\n",
    "This notebook demostrates classification of a 4DSTEM dataset containing a twin boundary.  The following steps are performed:\n",
    "- Load data\n",
    "- Initial visualization and virtual imaging\n",
    "- Bragg disk detection\n",
    "- Classification\n",
    "\n",
    "### Data\n",
    "The 4DSTEM data of a twin boundary used in this notebook was collected by Shiteng Zhao.\n",
    "\n",
    "To download the data, please [go here](https://drive.google.com/file/d/1sUrPEgM1wWyTh-LJ30lGUhcXklHj6ajC/view?usp=sharing).  Assuming you're running the notebook on your local computer, you should then need to place the file somewhere on your filesystem, and in the cell immediately after this one, update the variable `filepath_input` to reflect that path to the file.\n",
    "\n",
    "\n",
    "### Version info\n",
    "\n",
    "Last updated on 2019-09-08 with py4DSTEM version 0.9.17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this cell so that `fp_input` points to the data on your filesystem\n",
    "\n",
    "filepath_input = \"/Users/Ben/Work/Data/py4DSTEM_sampleData/classification_twinBoundary/twinBoundary_ShitengZhao20190115MEA.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import py4DSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and examine the data\n",
    "\n",
    "The next few cells load the datacube and vacuum probe, perform some basic analysis and visualization to  inspect each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine what's inside the data file\n",
    "\n",
    "py4DSTEM.file.io.read(filepath_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "datacube,_  = py4DSTEM.file.io.read(filepath_input,data_id='datacube')             # Get the 4D datacube\n",
    "\n",
    "_probe,_ = py4DSTEM.file.io.read(filepath_input,data_id='probe')                   # Get the vacuum probe\n",
    "probe = _probe.slices['probe']                                               # Unpack probe / probe kernel\n",
    "probe_kernel = _probe.slices['probe_kernel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max diffraction pattern\n",
    "\n",
    "A quick and useful way to examine a 4DSTEM datacube is to look at the maximal diffraction pattern - \n",
    "an array `dp_max` with the shape of the detector, in which the value assigned to each pixel in `dp_max` is\n",
    "the highest intensity the corresponding detector pixel sees over the entire 4D scan.  Any Bragg scattering\n",
    "across the region of the scan will then be included in a single diffraction image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_max = np.max(datacube.data,axis=(0,1))                                  # Get the maximal diffraction pattern\n",
    "py4DSTEM.visualize.show(dp_max,1,4)                                        # Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bright field image\n",
    "\n",
    "qx0,qy0 = 208,212                                                                     # Define detector geometry\n",
    "R = 18\n",
    "\n",
    "im_bf = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,qx0,qy0,R)       # Get image  \n",
    "\n",
    "py4DSTEM.visualize.show_circ(dp_max,1,4,center=(qx0,qy0),R=R,color='r',alpha=0.5)     # Show detector\n",
    "py4DSTEM.visualize.show(im_bf,5,5)                                                      # Show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect individual diffraction patterns\n",
    "\n",
    "rx1,ry1 = 3,4                                                                # Select scan positions\n",
    "rx2,ry2 = 6,21\n",
    "dp1 = datacube.data[rx1,ry1,:,:]                                            # Get DPs\n",
    "dp2 = datacube.data[rx2,ry2,:,:]\n",
    "colors=['r','b']\n",
    "\n",
    "fig,ax = py4DSTEM.visualize.show(im_bf,5,5,returnfig=True)                   # Show selected positions\n",
    "ax.scatter((ry1,ry2),(rx1,rx2),color=colors,s=500)\n",
    "plt.show()\n",
    "py4DSTEM.visualize.show_image_grid(lambda i:[dp1,dp2][i],1,2,axsize=(5,5),         # Show DPs\n",
    "                             get_bc=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtual dark-field imaging\n",
    "\n",
    "Looking at the diffraction patterns on the left and right of the scan, we can identify a twin boundary.  In `dp_max`, its easy to see where the twinned scattering vectors are.  So with `dp_max` in hand, we can use the same code that generated a bright field image, above, to make virtual dark-field images which light up the two twins present in this data.  Arguably, this is enough to call this data successfully classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtual dark-field imaging\n",
    "\n",
    "qx0_d1,qy0_d1 = 172,194                                                                  # Define detector geometries\n",
    "qx0_d2,qy0_d2 = 174,180\n",
    "R = 7\n",
    "\n",
    "im_df1 = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,qx0_d1,qy0_d1,R)  # Get virtual DF images\n",
    "im_df2 = py4DSTEM.process.virtualimage.get_virtualimage_circ(datacube,qx0_d2,qy0_d2,R)\n",
    "\n",
    "py4DSTEM.visualize.show_circ(dp_max,1,4,center=[(qx0_d1,qy0_d1),(qx0_d2,qy0_d2)],        # Show detectors\n",
    "                                        R=R,color=colors,alpha=0.5,figsize=(8,8))\n",
    "py4DSTEM.visualize.show_image_grid(lambda i:[im_df1,im_df2][i],2,1,axsize=(8,3),               # Show DF images\n",
    "                             contrast='minmax',get_bc=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The vacuum probe\n",
    "\n",
    "We also loaded `probe` and `probe_kernel`.\n",
    "`probe` is the electron probe in diffraction space over vacuum.\n",
    "`probe_kernel` is the vacuum probe with some additional processing to prepare it for the Bragg disk detection step.\n",
    "Preparing vacuum probes and kernels are discussed elsewhere - see TKTKTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.visualize.show(probe,contrast='minmax',figsize=(6,6))                           # Show the probe\n",
    "fig,ax = py4DSTEM.visualize.show(probe,contrast='minmax',figsize=(6,6),returnfig=True)   # Show it again,\n",
    "ax.set_ylim(200,216)                                                                     # this time zooming in\n",
    "ax.set_xlim(205,221)                                                                     # to the center\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.visualize.show_kernel(probe_kernel,R=10,L=80,W=2)            # Show the probe kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bragg disk detection\n",
    "\n",
    "In this step we find all the Bragg disks in the dataset.  The approach is to cross correlate the vacuum probe with each diffraction pattern, identifying the Bragg peak positions with the cross correlation maxima.\n",
    "\n",
    "This step is computationally expensive, and for most datasets can be quite slow (this example dataset is very small!).  It's usually a good idea to optimize parameters on a few test diffraction patterns before running the computation on the entire datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few diffraction patterns to test parameters on\n",
    "\n",
    "rx1_,ry1_ = 3,4                                                                # Select scan positions\n",
    "rx2_,ry2_ = 6,21\n",
    "dp1_ = datacube.data[rx1_,ry1_,:,:]                                             # Get DPs\n",
    "dp2_ = datacube.data[rx2_,ry2_,:,:]\n",
    "colors=['r','b']\n",
    "\n",
    "fig,ax = py4DSTEM.visualize.show(im_bf,5,5,returnfig=True)                     # Show selected positions\n",
    "ax.scatter((ry1_,ry2_),(rx1_,rx2_),color=colors,s=500)\n",
    "plt.show()\n",
    "py4DSTEM.visualize.show_image_grid(lambda i:[dp1_,dp2_][i],1,2,axsize=(5,5),           # Show DPs\n",
    "                                   get_bc=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune parameters and detect disks on the selected diffraction patterns\n",
    "\n",
    "corrPower = 1\n",
    "sigma = 5\n",
    "edgeBoundary = 20\n",
    "maxNumPeaks = 50\n",
    "minPeakSpacing = 10\n",
    "minRelativeIntensity = 0.05\n",
    "relativeToPeak = 1\n",
    "subpixel = 'poly'\n",
    "\n",
    "peaks = py4DSTEM.process.diskdetection.find_Bragg_disks_selected(             # Find Bragg peaks for a few\n",
    "                      datacube,                                               # selected diffraction patterns\n",
    "                      probe_kernel,\n",
    "                      (rx1_,rx2_), (rx2_,ry2_),\n",
    "                      corrPower=corrPower,\n",
    "                      sigma=sigma,\n",
    "                      edgeBoundary=edgeBoundary,\n",
    "                      minRelativeIntensity=minRelativeIntensity,\n",
    "                      relativeToPeak=relativeToPeak,\n",
    "                      minPeakSpacing=minPeakSpacing,\n",
    "                      maxNumPeaks=maxNumPeaks,\n",
    "                      subpixel=subpixel)\n",
    "\n",
    "py4DSTEM.visualize.show_points(dp1_,x=peaks[0].data['qx'],y=peaks[0].data['qy'],s=peaks[0].data['intensity'],\n",
    "                               point_color='r',bordercolor='r',min=1,max=4,figsize=(8,8))\n",
    "py4DSTEM.visualize.show_points(dp2_,x=peaks[1].data['qx'],y=peaks[1].data['qy'],s=peaks[1].data['intensity'],\n",
    "                               point_color='b',bordercolor='b',min=1,max=4,figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the full computation, using the parameters currently in memory\n",
    "\n",
    "braggpeaks = py4DSTEM.process.diskdetection.find_Bragg_disks(\n",
    "                              datacube,\n",
    "                              probe_kernel,\n",
    "                              corrPower=corrPower,\n",
    "                              sigma=sigma,\n",
    "                              edgeBoundary=edgeBoundary,\n",
    "                              minRelativeIntensity=minRelativeIntensity,\n",
    "                              relativeToPeak=relativeToPeak,\n",
    "                              minPeakSpacing=minPeakSpacing,\n",
    "                              maxNumPeaks=maxNumPeaks,\n",
    "                              subpixel=subpixel,\n",
    "                              verbose=True)\n",
    "braggpeaks.name = 'braggpeaks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bragg vector map\n",
    "\n",
    "\n",
    "Following disk detection, we can compute the Bragg vector map, defined as the sum of all the detected Bragg disk centers, weighted by their cross correlation intensities.\n",
    "The BVM is roughly interpretable as a density map of Bragg scattering vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "braggvectormap = py4DSTEM.process.diskdetection.get_bragg_vector_map(braggpeaks,datacube.Q_Nx,datacube.Q_Ny)\n",
    "\n",
    "py4DSTEM.visualize.show(braggvectormap,0,5,cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "Depending on the dataset, some calibration may be helpful at this point, including correction of diffraction shifts and/or elliptical distortions.  These are essential in many datasets.  Calibration of the detector pixel size and the rotational offset of real/reciprocal space can also be performed now.\n",
    "\n",
    "In this dataset, calibration is not necessary to complete the classification, so will be skipped here for succinctness.  Sample calibration code and discussion can be found elsewhere - see TKTKTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "In this step we perform the classification using the detected Bragg peaks.  The algorithm used here is as follows:\n",
    "\n",
    "1. Maxima in the Bragg vector map are used to segment k-space using a Voronoi tesselation.  Let's call the number of regions `N`.\n",
    "- For each diffraction pattern, a feature vector is contructed consisting of `N` Boolean values, indicating whether Bragg scattering was detected through each k-space region in each diffraction pattern.\n",
    "- An initial classification is performed by identifying scan positions which are most likely to have the same Bragg peaks\n",
    "- The initial classification is refined using non-negative matrix factorization\n",
    "\n",
    "With the classes in hand, we also compute the class diffraction patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qx, Qy, intensity = py4DSTEM.process.utils.get_maxima_2D(                    # Find the maxima of the BVM\n",
    "                                braggvectormap,\n",
    "                                sigma=1,\n",
    "                                edgeBoundary=20,\n",
    "                                minSpacing=8,\n",
    "                                minRelativeIntensity=0.005,\n",
    "                                relativeToPeak=1,\n",
    "                                maxNumPeaks=100,\n",
    "                                subpixel=True)\n",
    "N = len(Qx)                                                                  # The feature vector length\n",
    "\n",
    "py4DSTEM.visualize.show_points(braggvectormap,x=Qx,y=Qy,s=intensity,min=0,max=5,cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py4DSTEM.visualize.show_voronoi(braggvectormap,Qx,Qy,min=0,max=2,cmap='jet')         # Display the voronoi tesselation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a maximum distance from the BVM maxima that a given Bragg peak can be and still be considered\n",
    "# an instance of this peak\n",
    "\n",
    "max_dist = 12\n",
    "\n",
    "py4DSTEM.visualize.show_voronoi(braggvectormap,Qx,Qy,min=0,max=2,cmap='jet',max_dist=max_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = py4DSTEM.process.classification.BraggVectorClassification(          # Set up classification Class\n",
    "                        braggpeaks,Qx,Qy,max_dist=max_dist,X_is_boolean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.get_initial_classes_by_cooccurrence(                     # Generate initial classes.\n",
    "                        thresh=0.3,\n",
    "                        BP_fraction_thresh=0.1,\n",
    "                        max_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show initial class images\n",
    "\n",
    "colors=['r','b']\n",
    "\n",
    "py4DSTEM.visualize.show_image_grid(lambda i: classification.get_class_image(i),2,1,axsize=(8,3),\n",
    "                                contrast='minmax',get_bc=lambda i: colors[i],titlesize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show class bragg peak weights\n",
    "\n",
    "py4DSTEM.visualize.show_class_BPs_grid(braggvectormap,H=1,W=2,x=Qx,y=Qy,s2=25,\n",
    "                                       min=0,max=2,cmap='jet',titlesize=18,\n",
    "                                       get_s=lambda i:200*classification.get_class_BPs(i),\n",
    "                                       get_bc=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the class diffraction patterns\n",
    "\n",
    "class_dps = np.zeros((datacube.Q_Nx,datacube.Q_Ny,classification.N_c))\n",
    "for i in range(classification.N_c):\n",
    "    class_dps[:,:,i] = py4DSTEM.process.classification.get_class_DP(\n",
    "                                datacube,\n",
    "                                classification.get_class_image(i)\n",
    "    )\n",
    "    \n",
    "py4DSTEM.visualize.show_image_grid(lambda i: class_dps[:,:,i],\n",
    "                                   1,2,axsize=(6,6),cmap='gray',min=1,max=4,get_bc=lambda i: colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a dark reference to perform background subtraction\n",
    "\n",
    "darkref = py4DSTEM.process.preprocess.get_darkreference(datacube,N_frames=50,width_x=10,width_y=10)\n",
    "py4DSTEM.visualize.show(darkref,contrast='minmax',figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute class diffraction patterns\n",
    "\n",
    "class_dps = np.zeros((datacube.Q_Nx,datacube.Q_Ny,classification.N_c))\n",
    "for i in range(classification.N_c):\n",
    "    class_dps[:,:,i] = py4DSTEM.process.classification.get_class_DP(\n",
    "                                datacube,\n",
    "                                classification.get_class_image(i),\n",
    "                                darkref=darkref\n",
    "    )\n",
    "    \n",
    "py4DSTEM.visualize.show_image_grid(lambda i: class_dps[:,:,i],\n",
    "                                   1,2,axsize=(6,6),cmap='gray',min=1,max=4,get_bc=lambda i: colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine classes using non-negative matrix factorization\n",
    "\n",
    "classification.nmf(max_iterations=200)\n",
    "classification.accept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the classes\n",
    "\n",
    "py4DSTEM.visualize.show_image_grid(lambda i: classification.get_class_image(i),2,1,axsize=(8,3),\n",
    "                                   contrast='minmax',get_bc=lambda i: colors[i],titlesize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show class bragg peak weights\n",
    "\n",
    "py4DSTEM.visualize.show_class_BPs_grid(braggvectormap,H=1,W=2,x=Qx,y=Qy,s2=25,min=0,max=2,cmap='jet',titlesize=18,\n",
    "                                       get_s=lambda i:200*classification.get_class_BPs(i),get_bc=lambda i:colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class diffraction patterns\n",
    "\n",
    "class_dps = np.zeros((datacube.Q_Nx,datacube.Q_Ny,classification.N_c))\n",
    "for i in range(classification.N_c):\n",
    "    class_dps[:,:,i] = py4DSTEM.process.classification.get_class_DP(\n",
    "                                datacube,\n",
    "                                classification.get_class_image(i),\n",
    "                                darkref=darkref\n",
    "    )\n",
    "    \n",
    "py4DSTEM.visualize.show_image_grid(lambda i: class_dps[:,:,i],\n",
    "                                   1,2,axsize=(6,6),cmap='gray',min=1,max=4,get_bc=lambda i: colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
